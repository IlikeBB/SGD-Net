{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f59efbc4490>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np, torch, os, glob, nibabel as nib, multiprocessing, pandas as pd, sys\n",
    "import torch.backends.cudnn as cudnn, torchio as tio, random\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch.backends.cudnn as cudnn\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from sklearn.metrics import *\n",
    "sys.path.append(\"..\")\n",
    "from utils.model_res import generate_model\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.utils.data import DataLoader\n",
    "from scipy import ndimage\n",
    "from tqdm import tqdm   \n",
    "\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True\n",
    "random.seed(1234)\n",
    "torch.manual_seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load csv label\n",
    "if True:\n",
    "    csv_path = '../20211104_label_1-350_1.5&3.0.csv'\n",
    "    table_3t =  pd.read_csv(csv_path)\n",
    "    # table_3t = table[table['1/0: 3T/1.5T MRI']==1.0]\n",
    "    table_3t_test = table_3t[table_3t['Valid data']=='V']\n",
    "    table_3t_test = np.array(table_3t_test[table_3t_test['排除']=='Test data'])\n",
    "    nii_3t_test = sorted([i for i in os.listdir(os.path.join('../dataset/S2_data1.5&3.0/','test'))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subject Function Building\n",
    "def tio_process(nii_3t_, table_3t_, basepath_='./dataset/S2_data/train/'):\n",
    "    subjects_ = []\n",
    "    for  (nii_path, nii_table) in zip(nii_3t_ , table_3t_):\n",
    "        if (params['S2_type']=='ap') and (nii_table[3]=='A' or nii_table[3]=='P'):\n",
    "            subject = tio.Subject(\n",
    "                dwi = tio.ScalarImage(os.path.join(basepath_, nii_path)), \n",
    "                ap = nii_table[3], \n",
    "                score=[])\n",
    "            subjects_.append(subject)\n",
    "        elif (params['S2_type']=='nl'):\n",
    "            subject = tio.Subject(\n",
    "                dwi = tio.ScalarImage(os.path.join(basepath_, nii_path)), \n",
    "                nl  = nii_table[4], \n",
    "                score=[])\n",
    "            subjects_.append(subject)\n",
    "    return subjects_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 78/78 [00:24<00:00,  3.14it/s]\n",
      "100%|██████████| 78/78 [00:05<00:00, 13.49it/s]\n",
      "100%|██████████| 80/80 [00:22<00:00,  3.60it/s]\n",
      "100%|██████████| 80/80 [00:05<00:00, 14.14it/s]\n"
     ]
    }
   ],
   "source": [
    "def S1_evaluate(model, valid_loader):\n",
    "    predict_array = []\n",
    "    model.eval()\n",
    "    stream = tqdm(valid_loader)\n",
    "    with torch.no_grad():\n",
    "        for i, images in enumerate(stream, start=1):\n",
    "            images = images['dwi'][tio.DATA]\n",
    "            # torch.Size([1, 1, 384, 384, 26])\n",
    "            images = images.squeeze(0)\n",
    "            images = images.permute(3,0,1,2)\n",
    "            # .permute(1,0,2).\n",
    "            images = images.to(device)\n",
    "            output =  model(images)\n",
    "            output = torch.sigmoid(output)\n",
    "            output = (output - output.min()) / (output.max() - output.min() + 1e-8) #****!!!!\n",
    "            # print(torch.max(output), torch.min(output))\n",
    "            output = output.cpu() \n",
    "            images = images.cpu() \n",
    "            # torch.Size([26, 1, 384, 384])\n",
    "            pred_mask = torch.where(output>0.5, images, images*0)\n",
    "            pred_mask = pred_mask.cpu() \n",
    "            if False:\n",
    "                for idx in range(26):\n",
    "                    fig = plt.figure()\n",
    "                    \n",
    "                    ax1 = fig.add_subplot(1,3,1)\n",
    "                    ax1.imshow(np.squeeze(images[idx], axis=0), cmap='bone')\n",
    "                    ax1.get_xaxis().set_visible(False)\n",
    "                    ax1.get_yaxis().set_visible(False)\n",
    "\n",
    "                    ax2 = fig.add_subplot(1,3,2)\n",
    "                    ax2.imshow(np.squeeze(output[idx]>0.3, axis=0), cmap='bone')\n",
    "                    ax2.get_xaxis().set_visible(False)\n",
    "                    ax2.get_yaxis().set_visible(False)\n",
    "                    \n",
    "                    ax3 = fig.add_subplot(1,3,3)\n",
    "                    ax3.imshow(np.squeeze(pred_mask[idx], axis=0), cmap='bone')\n",
    "                    ax3.get_xaxis().set_visible(False)\n",
    "                    ax3.get_yaxis().set_visible(False)\n",
    "                    plt.show()\n",
    "                    plt.close(fig)\n",
    "            \n",
    "            pred_mask = (pred_mask.permute(1,2,3,0))\n",
    "            # torch.Size([1, 1, 384, 384, 26])\n",
    "            predict_array.append(pred_mask)\n",
    "            # if i ==1:\n",
    "            #     break\n",
    "    return predict_array\n",
    "\n",
    "def change_subject_img(subject_, tesnor_ary):\n",
    "    for idx, i in enumerate(subject_):\n",
    "        if False:\n",
    "            print( subject_[idx]['dwi'].shape)\n",
    "            for idx2 in range(26):\n",
    "                fig = plt.figure(figsize=(12,12))\n",
    "                ax1 = fig.add_subplot(1,3,1)\n",
    "                ax1.imshow(np.squeeze((subject_[idx]['dwi'][tio.DATA])[...,idx2], axis=0), cmap='bone')\n",
    "                ax1.get_xaxis().set_visible(False)\n",
    "                ax1.get_yaxis().set_visible(False)\n",
    "                ax2 = fig.add_subplot(1,3,2)\n",
    "                ax2.imshow(np.squeeze((tesnor_ary[idx])[...,idx2], axis=0), cmap='bone')\n",
    "                ax2.get_xaxis().set_visible(False)\n",
    "                ax2.get_yaxis().set_visible(False)\n",
    "                plt.show()\n",
    "                plt.close(fig)\n",
    "        subject_[idx]['dwi'].set_data(tesnor_ary[idx])\n",
    "        # image =  subject_[idx]['dwi'][tio.DATA]\n",
    "    return subject_\n",
    "\n",
    "def label2value(label):\n",
    "    if params[\"S2_type\"]=='nl':\n",
    "        target = [0 if i=='N' else 1 for i in label]\n",
    "    else:\n",
    "        target = [0 if i=='A' else 1 for i in label]\n",
    "    return torch.LongTensor(target).to(device)\n",
    "\n",
    "def S2_evaluate(model,valid_loader):\n",
    "    predict_array = {'target':[], 'predict':[]}\n",
    "    model.eval()\n",
    "    stream_v = tqdm(S2_subjects)\n",
    "    with torch.no_grad():\n",
    "        for i, data in enumerate(stream_v, start=1):\n",
    "            images = data['dwi'][tio.DATA].to(device).unsqueeze(0)\n",
    "            target = label2value(data[params[\"S2_type\"]])\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(images).squeeze(1)\n",
    "            output = torch.sigmoid(output)\n",
    "            output = (output - output.min()) / (output.max() - output.min() + 1e-8) #****!!!!\n",
    "            # print(output)\n",
    "            _, outputs = torch.max(output, 1)\n",
    "            predict_array['predict'].append(outputs.item())\n",
    "            predict_array['target'].append(target.item())\n",
    "    return predict_array\n",
    "if True:\n",
    "    test_transform = tio.Compose([])\n",
    "    # test_transform = tio.Compose([tio.ZNormalization(masking_method=tio.ZNormalization.mean)])\n",
    "    test_transform2 = tio.Compose([tio.ZNormalization(masking_method=tio.ZNormalization.mean)])\n",
    "    S1_weight = '../checkpoint/2021.11.23.t2 - 2DDenseNet121Unet/2DDenseNet121Unet - lr_0.001 - FTL --  epoch:105 | vDice:0.7908 | vLoss:0.0634.pt'\n",
    "    S2_weight_ap = '../checkpoint/2021.11.25.t2 - 3DResNet18 - ap/ap - 3dresnet18 - lr_0.001 - FL --  epoch:93 | vLoss:0.01088 | vAcc:100.0.pt'\n",
    "    S2_weight_nl = '../checkpoint/2021.11.24.t2 - 3DResNet18 - nl/nl - 3dresnet18 - lr_0.001 - FL --  epoch:22 | vLoss:0.01902 | vAcc:93.75.pt'\n",
    "    S2_weight_stack = {'ap': S2_weight_ap, 'nl': S2_weight_nl}\n",
    "    S1_checkpoint = torch.load(S1_weight, map_location=torch.device(device))\n",
    "    S1_model = smp.Unet(encoder_name='densenet121', encoder_weights=None, in_channels=1, classes=1)\n",
    "    S1_model.load_state_dict(S1_checkpoint['model_state_dict'])\n",
    "    S1_model.to(device)\n",
    "    S2_reply = {'ap': [], 'nl':[]}\n",
    "for idx, i in enumerate(['ap', 'nl']):\n",
    "# for idx, i in enumerate(['nl']):\n",
    "    # ///////////////////////////////////////////////////\n",
    "    S2_model = generate_model(model_depth=18, n_input_channels=1, n_classes=2)\n",
    "    S2_checkpoint= torch.load(S2_weight_stack[i], map_location=torch.device(device))\n",
    "    S2_model.load_state_dict(S2_checkpoint['model_state_dict'])\n",
    "    S2_model.to(device)\n",
    "    # //////////////////////////////////////////////////\n",
    "    params = {\"S1_type\": None, \"S2_type\": i}\n",
    "    S1_subjects = tio_process(nii_3t_test, table_3t_test, basepath_ = '../dataset/S2_data1.5&3.0/test/')\n",
    "    S1_set = tio.SubjectsDataset(S1_subjects, transform=test_transform)\n",
    "    test_loader = torch.utils.data.DataLoader(S1_set, batch_size=1, shuffle=False, num_workers=4)\n",
    "    S1_reply = S1_evaluate(S1_model, test_loader)\n",
    "    S2_subjects = change_subject_img(S1_subjects, S1_reply)\n",
    "    S2_reply[i].append(S2_evaluate(S2_model, S2_subjects))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ap  -   Accuracy  : 91.0 %\n",
      "ap  -   Sensitivity  : 0.96296\n",
      "ap  -   Specificity  : 0.88235\n",
      "nl  -   Accuracy  : 93.0 %\n",
      "nl  -   Sensitivity  : 0.97297\n",
      "nl  -   Specificity  : 0.88372\n"
     ]
    }
   ],
   "source": [
    "for i in ['ap', 'nl']:\n",
    "    GT =np.array(S2_reply[i][0]['target'])\n",
    "    SR = np.array(S2_reply[i][0]['predict'])\n",
    "    TP = int((SR * GT).sum()) #TP\n",
    "    FN = int((GT * (1-SR)).sum()) #FN\n",
    "    TN = int(((1-GT) * (1-SR)).sum()) #TN\n",
    "    FP = int(((1-GT) * SR).sum()) #FP\n",
    "    print(f'{i}  -   Accuracy  :', round((TP + TN)/(TP + TN + FP + FN), 2)*100, '%')\n",
    "    print(f'{i}  -   Sensitivity  :', round(float(TP)/(float(TP+FN) + 1e-6), 5))\n",
    "    print(f'{i}  -   Specificity  :', round(float(TN)/(float(TN+FP) + 1e-6), 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11/23 only 3.0T\n",
    "#### ap  -   Accuracy  : 91.0 %\n",
    "#### ap  -   Sensitivity  : 0.71429\n",
    "#### ap  -   Specificity  : 1.0\n",
    "#### nl  -   Accuracy  : 93.0 %\n",
    "#### nl  -   Sensitivity  : 0.95833\n",
    "#### nl  -   Specificity  : 0.90476"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# for i in test_loader2:\n",
    "#     print(i['dwi'][tio.DATA].shape)\n",
    "#     image = i['dwi'][tio.DATA].squeeze(0)\n",
    "#     for idx2 in range(26):\n",
    "#         fig = plt.figure()\n",
    "#         ax1 = fig.add_subplot(1,1,1)\n",
    "#         print(idx2+1)\n",
    "#         ax1.imshow(np.squeeze(image[...,idx2], axis=0), cmap='bone')\n",
    "#         # ax1.get_xaxis().set_visible(False)\n",
    "#         # ax1.get_yaxis().set_visible(False)\n",
    "#         plt.show()\n",
    "#         plt.close(fig)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c7173b66b0b7b9d3ef17108453430ecf43b59c5f40b531d440cd8bb0e5f91238"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit ('torch-SGD': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
